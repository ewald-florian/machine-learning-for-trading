{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cba3852",
   "metadata": {},
   "source": [
    "# Experiment with Tune in the RayTradingEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be8bd9",
   "metadata": {},
   "source": [
    "- Tune is a Python library for experiment execution and hyperparameter tuning at any scale. You can tune your favorite machine learning framework\n",
    "- Tune further integrates with a wide range of additional hyperparameter optimization tools\n",
    "- Tune allows you to transparently parallelize across multiple GPUs and multiple nodes. <p>\n",
    "- [Tune Documentation](https://docs.ray.io/en/latest/tune/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa19b00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ray_trading_env:ray_trading_env logger started.\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import environ\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import pprint\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "from ray_trading_env import RayTradingEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f26a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8492e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in local mode (to access csv file in directory)\n",
    "# local_mode = bool(int(environ.get('RAY_LOCAL', '0')))\n",
    "# ray.init(local_mode=local_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496e93d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 17:35:46,672\tWARNING services.py:2002 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.8', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '10.1.150.226', 'raylet_ip_address': '10.1.150.226', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-06-27_17-35-46_176858_49782/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-06-27_17-35-46_176858_49782/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-06-27_17-35-46_176858_49782', 'metrics_export_port': 52568, 'gcs_address': '10.1.150.226:41082', 'address': '10.1.150.226:41082', 'node_id': '2c1a0853f1cdcb35b693c5864074fbad331c34a67cd4e47066d79069'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f437ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will happen:\n",
    "# - Tune will run several Rllib trainers in parallel\n",
    "# - The number depends on the number of grid searches we do, i.e. \n",
    "# every possible lr has to to combined with every possible train_batch_sizer\n",
    "# - So, here we will have 4 trials\n",
    "# - The opportunity to run them in parallel depends on the hardware\n",
    "# - By default, a single PPO trial uses 3 CPUs (2 actors which step\n",
    "# through two seperate environments and one local lerner-> the local \n",
    "# lerner is responsible for the training step (update the NN) and after\n",
    "# the training step it broadcasts the network back to the two actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3023bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config dict for Rllib\n",
    "config = {\n",
    "    \"env\": RayTradingEnvironment,\n",
    "    \"env_config\": {\n",
    "        \"config\": {\n",
    "            \"trading_days\": 252,\n",
    "            \"trading_cost_bps\": 1e-3,\n",
    "            \"time_cost_bps\": 1e-4,\n",
    "            \"ticker\": \"AAPL\",\n",
    "            # note: need to specify path when using Tune\n",
    "            \"data_path\": \"/home/jovyan/machine-learning-for-trading/AAPL_prices.csv\",\n",
    "            #\"max_episode_steps\": 252,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"create_env_on_driver\": True,\n",
    "    # horizon needs to be specified if the env has no \n",
    "    # max_number_of_steps-like parameter\n",
    "    \"horizon\" : 252,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624adfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same config file as for PPOTrainer\n",
    "tune_config = config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724bb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config hyperparameter search for learning rates and train_batch_size\n",
    "# pass lists with possible values\n",
    "tune_config[\"lr\"] = tune.grid_search([0.0001, 0.5]) \n",
    "tune_config[\"train_batch_size\"] = tune.grid_search([3000, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7489303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env': ray_trading_env.RayTradingEnvironment,\n",
       " 'env_config': {'config': {'trading_days': 252,\n",
       "   'trading_cost_bps': 0.001,\n",
       "   'time_cost_bps': 0.0001,\n",
       "   'ticker': 'AAPL',\n",
       "   'data_path': '/home/jovyan/machine-learning-for-trading/AAPL_prices.csv'}},\n",
       " 'create_env_on_driver': True,\n",
       " 'horizon': 252,\n",
       " 'lr': {'grid_search': [0.0001, 0.5]},\n",
       " 'train_batch_size': {'grid_search': [3000, 4000]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65151de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopping criteria\n",
    "stop = {\n",
    "    # keys used here can be anything present in the above `rllib_trainer.train()` output dict.\n",
    "    \"training_iteration\": 5,\n",
    "    \"episode_reward_mean\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5442cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiment\n",
    "tune.run(\n",
    "    \"PPO\", # --> PPOTrainer\n",
    "    config=tune_config,\n",
    "    stop=stop,\n",
    "\n",
    "    # Note: Trainers will not be returned.\n",
    "    # Tune creats Trainers internally, runs them in parallel and destroys them afterwards\n",
    "    checkpoint_at_end=True,  # ... create a checkpoint when done.\n",
    "    checkpoint_freq=2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a97b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = {\n",
    "    \"training_iteration\": 100, \n",
    "    \"episode_reward_mean\": 60.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4fedac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update tune config (without grid search)\n",
    "tune_config[\"lr\"] = 0.0001\n",
    "tune_config[\"train_batch_size\"] = 3000\n",
    "tune_config[\"num_workers\"] = 5\n",
    "tune_config[\"num_envs_per_worker\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a4fe8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env': ray_trading_env.RayTradingEnvironment,\n",
       " 'env_config': {'config': {'trading_days': 252,\n",
       "   'trading_cost_bps': 0.001,\n",
       "   'time_cost_bps': 0.0001,\n",
       "   'ticker': 'AAPL',\n",
       "   'data_path': '/home/jovyan/machine-learning-for-trading/AAPL_prices.csv'}},\n",
       " 'create_env_on_driver': True,\n",
       " 'horizon': 252,\n",
       " 'lr': 0.0001,\n",
       " 'train_batch_size': 3000,\n",
       " 'num_workers': 5,\n",
       " 'num_envs_per_worker': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002feaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in analysis object\n",
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    config=tune_config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48e73df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = analysis.get_best_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29252ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checkpoint(persistent, /home/jovyan/ray_results/PPO/PPO_RayTradingEnvironment_f9977_00000_0_2022-06-27_17-45-46/checkpoint_000100/checkpoint-100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b02d9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>num_agent_steps_sampled</th>\n",
       "      <th>num_agent_steps_trained</th>\n",
       "      <th>num_env_steps_sampled</th>\n",
       "      <th>num_env_steps_trained</th>\n",
       "      <th>...</th>\n",
       "      <th>info/learner/default_policy/learner_stats/entropy_coeff</th>\n",
       "      <th>config/create_env_on_driver</th>\n",
       "      <th>config/env</th>\n",
       "      <th>config/env_config</th>\n",
       "      <th>config/horizon</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>config/num_envs_per_worker</th>\n",
       "      <th>config/num_workers</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.707665</td>\n",
       "      <td>-0.421143</td>\n",
       "      <td>0.348181</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;class 'ray_trading_env.RayTradingEnvironment'&gt;</td>\n",
       "      <td>{'config': {'data_path': '/home/jovyan/machine...</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>/home/jovyan/ray_results/PPO/PPO_RayTradingEnv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0            1.707665           -0.421143             0.348181   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "0             252.0                   0                    5   \n",
       "\n",
       "   num_agent_steps_sampled  num_agent_steps_trained  num_env_steps_sampled  \\\n",
       "0                   300000                   300000                 300000   \n",
       "\n",
       "   num_env_steps_trained  ...  \\\n",
       "0                 300000  ...   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/entropy_coeff  \\\n",
       "0                                                0.0         \n",
       "\n",
       "   config/create_env_on_driver  \\\n",
       "0                         True   \n",
       "\n",
       "                                        config/env  \\\n",
       "0  <class 'ray_trading_env.RayTradingEnvironment'>   \n",
       "\n",
       "                                   config/env_config  config/horizon  \\\n",
       "0  {'config': {'data_path': '/home/jovyan/machine...             252   \n",
       "\n",
       "   config/lr  config/num_envs_per_worker config/num_workers  \\\n",
       "0     0.0001                           5                  5   \n",
       "\n",
       "  config/train_batch_size                                             logdir  \n",
       "0                    3000  /home/jovyan/ray_results/PPO/PPO_RayTradingEnv...  \n",
       "\n",
       "[1 rows x 74 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ead66ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 1656351946.7440944, 'timestamp': 1656352094.4915183}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d043c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
